{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/andersy005/video-game-graphics-to-reality-and-back/blob/master/image_translation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DhilG5wdW1Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "fc816e9d-6efc-4d27-84b5-370e687ffc0c"
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0\n",
        "!pip install image\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0)\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.1.0\n",
            "    Uninstalling Pillow-5.1.0:\n",
            "      Successfully uninstalled Pillow-5.1.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NHYVJ7iQ64wG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0d0bb6b-3ac3-473e-afad-fd5d270872e9"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "Nt30TK5qh7bS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "!wget --header 'Host: doc-0o-58-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:59.0) Gecko/20100101 Firefox/59.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/drive/u/1/folders/1B56WZ20ODejt7MAwFr0a2HnMJ0fz4VlN' --header 'Cookie: AUTH_e1273drrbkihn7uunefac5g2nh6fppao=07610261954870412584|1523390400000|kf36r1s9jup16ems1p1f2sckdgrlvbhm; NID=123=lBPWjtG4k1sU7Dd0qsq5jpbqEiDrMBU8x0r6kdqXBCf-pCwxt9y7UdTTVaEFzLR7u5w-wq6dp0xKDTIsDb6QCnL0jNICERWUAuRHrxjQlpzo8gI8bqEpJJBDhN1T2RNR' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://doc-0o-58-docs.googleusercontent.com/docs/securesc/u8k4a259k8v0rijo1dv2q4t69g74544s/il57erfe3koja1994495ashvpr49mjfs/1523390400000/07610261954870412584/07610261954870412584/1gKCTPV_pCWaIEuiQ5IWP8rQSh040ezOL?h=11006290462901738094&e=download' --output-document 'city.tar.gz'\n",
        "!wget --header 'Host: doc-14-58-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:59.0) Gecko/20100101 Firefox/59.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/drive/u/1/folders/1B56WZ20ODejt7MAwFr0a2HnMJ0fz4VlN' --header 'Cookie: AUTH_e1273drrbkihn7uunefac5g2nh6fppao=07610261954870412584|1523390400000|kf36r1s9jup16ems1p1f2sckdgrlvbhm; NID=123=lBPWjtG4k1sU7Dd0qsq5jpbqEiDrMBU8x0r6kdqXBCf-pCwxt9y7UdTTVaEFzLR7u5w-wq6dp0xKDTIsDb6QCnL0jNICERWUAuRHrxjQlpzo8gI8bqEpJJBDhN1T2RNR' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://doc-14-58-docs.googleusercontent.com/docs/securesc/u8k4a259k8v0rijo1dv2q4t69g74544s/3le4pio11hb399ub230qat6883ggjv5n/1523390400000/07610261954870412584/07610261954870412584/1TxNprMLCTVnTWV9QIYDve5mv_DjOsCNb?h=11006290462901738094&e=download' --output-document 'gta.tar.gz'\n",
        "!tar -zxvf gta.tar.gz\n",
        "!tar -zxvf city.tar.gz\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTaQAFTrgOJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnCQ6AWxlJXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class G12(nn.Module):\n",
        "    \"\"\"Generator for transfering from mnist to svhn\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G12, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        \n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        \n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "        \n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 3, 32, 32)\n",
        "        return out\n",
        "    \n",
        "class G21(nn.Module):\n",
        "    \"\"\"Generator for transfering from svhn to mnist\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G21, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        \n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        \n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "        \n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 1, 32, 32)\n",
        "        return out\n",
        "    \n",
        "class D1(nn.Module):\n",
        "    \"\"\"Discriminator for mnist.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D1, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out\n",
        "\n",
        "class D2(nn.Module):\n",
        "    \"\"\"Discriminator for svhn.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D2, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8jm0K8cgPda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import pickle\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torchvision import transforms, utils\n",
        "#from models.model import G12, G21\n",
        "#from models.model import D1, D2\n",
        "\n",
        "\n",
        "class Solver(object):\n",
        "    def __init__(self, config, gta_loader, city_loader):\n",
        "        self.gta_loader = gta_loader\n",
        "        self.city_loader = city_loader\n",
        "        self.g12 = None\n",
        "        self.g21 = None\n",
        "        self.d1 = None\n",
        "        self.d2 = None\n",
        "        self.g_optimizer = None\n",
        "        self.d_optimizer = None\n",
        "        self.use_reconst_loss = config.use_reconst_loss\n",
        "        self.use_labels = config.use_labels\n",
        "        self.num_classes = config.num_classes\n",
        "        self.beta1 = config.beta1\n",
        "        self.beta2 = config.beta2\n",
        "        self.g_conv_dim = config.g_conv_dim\n",
        "        self.d_conv_dim = config.d_conv_dim\n",
        "        self.train_iters = config.train_iters\n",
        "        self.batch_size = config.batch_size\n",
        "        self.lr = config.lr\n",
        "        self.log_step = config.log_step\n",
        "        self.sample_step = config.sample_step\n",
        "        self.sample_path = config.sample_path\n",
        "        self.model_path = config.model_path\n",
        "        self.build_model()\n",
        "        \n",
        "    def build_model(self):\n",
        "        \"\"\"Builds a generator and a discriminator.\"\"\"\n",
        "        self.g12 = G12(conv_dim=self.g_conv_dim)\n",
        "        self.g21 = G21(conv_dim=self.g_conv_dim)\n",
        "        self.d1 = D1(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n",
        "        self.d2 = D2(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n",
        "        \n",
        "        g_params = list(self.g12.parameters()) + list(self.g21.parameters())\n",
        "        d_params = list(self.d1.parameters()) + list(self.d2.parameters())\n",
        "        \n",
        "        self.g_optimizer = optim.Adam(g_params, self.lr, [self.beta1, self.beta2])\n",
        "        self.d_optimizer = optim.Adam(d_params, self.lr, [self.beta1, self.beta2])\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            self.g12.cuda()\n",
        "            self.g21.cuda()\n",
        "            self.d1.cuda()\n",
        "            self.d2.cuda()\n",
        "    \n",
        "    def merge_images(self, sources, targets, k=10):\n",
        "        _, _, h, w = sources.shape\n",
        "        row = int(np.sqrt(self.batch_size))\n",
        "        merged = np.zeros([3, row*h, row*w*2])\n",
        "        for idx, (s, t) in enumerate(zip(sources, targets)):\n",
        "            i = idx // row\n",
        "            j = idx % row\n",
        "            merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "            merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "        return merged.transpose(1, 2, 0)\n",
        "    \n",
        "    def to_var(self, x):\n",
        "        \"\"\"Converts numpy to variable.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cuda()\n",
        "        return Variable(x)\n",
        "    \n",
        "    def to_data(self, x):\n",
        "        \"\"\"Converts variable to numpy.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cpu()\n",
        "        return x.data.numpy()\n",
        "    \n",
        "    def reset_grad(self):\n",
        "        \"\"\"Zeros the gradient buffers.\"\"\"\n",
        "        self.g_optimizer.zero_grad()\n",
        "        self.d_optimizer.zero_grad()\n",
        "\n",
        "    def train(self):\n",
        "        gta_iter = iter(self.gta_loader)\n",
        "        city_iter = iter(self.city_loader)\n",
        "        iter_per_epoch = min(len(gta_iter), len(city_iter))\n",
        "        \n",
        "        # fixed city and gta for sampling\n",
        "        fixed_gta = self.to_var(gta_iter.next())\n",
        "        fixed_city = self.to_var(city_iter.next())\n",
        "        \n",
        "        # loss if use_labels = True\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        for step in range(self.train_iters+1):\n",
        "            # reset data_iter for each epoch\n",
        "            if (step+1) % iter_per_epoch == 0:\n",
        "                city_iter = iter(self.city_loader)\n",
        "                gta_iter = iter(self.gta_loader)\n",
        "            \n",
        "            # load gta and city dataset\n",
        "            gta = gta_iter.next() \n",
        "            gta = self.to_var(gta)\n",
        "            city = city_iter.next() \n",
        "            city = self.to_var(city)\n",
        "\n",
        "            if self.use_labels:\n",
        "                city_fake_labels = self.to_var(\n",
        "                    torch.Tensor([self.num_classes]*gta.size(0)).long())\n",
        "                gta_fake_labels = self.to_var(\n",
        "                    torch.Tensor([self.num_classes]*city.size(0)).long())\n",
        "            \n",
        "            #============ train D ============#\n",
        "            \n",
        "            # train with real images\n",
        "            self.reset_grad()\n",
        "            out = self.d1(city)\n",
        "            if self.use_labels:\n",
        "                d1_loss = criterion(out, m_labels)\n",
        "            else:\n",
        "                d1_loss = torch.mean((out-1)**2)\n",
        "            \n",
        "            out = self.d2(gta)\n",
        "            if self.use_labels:\n",
        "                d2_loss = criterion(out, s_labels)\n",
        "            else:\n",
        "                d2_loss = torch.mean((out-1)**2)\n",
        "            \n",
        "            d_city_loss = d1_loss\n",
        "            d_gta_loss = d2_loss\n",
        "            d_real_loss = d1_loss + d2_loss\n",
        "            d_real_loss.backward()\n",
        "            self.d_optimizer.step()\n",
        "            \n",
        "            # train with fake images\n",
        "            self.reset_grad()\n",
        "            fake_gta = self.g12(city)\n",
        "            out = self.d2(fake_gta)\n",
        "            if self.use_labels:\n",
        "                d2_loss = criterion(out, gta_fake_labels)\n",
        "            else:\n",
        "                d2_loss = torch.mean(out**2)\n",
        "            \n",
        "            fake_city = self.g21(gta)\n",
        "            out = self.d1(fake_city)\n",
        "            if self.use_labels:\n",
        "                d1_loss = criterion(out, city_fake_labels)\n",
        "            else:\n",
        "                d1_loss = torch.mean(out**2)\n",
        "            \n",
        "            d_fake_loss = d1_loss + d2_loss\n",
        "            d_fake_loss.backward()\n",
        "            self.d_optimizer.step()\n",
        "            \n",
        "            #============ train G ============#\n",
        "            \n",
        "            # train city-gta-city cycle\n",
        "            self.reset_grad()\n",
        "            fake_gta = self.g12(city)\n",
        "            out = self.d2(fake_gta)\n",
        "            reconst_city = self.g21(fake_gta)\n",
        "            if self.use_labels:\n",
        "                g_loss = criterion(out, m_labels) \n",
        "            else:\n",
        "                g_loss = torch.mean((out-1)**2) \n",
        "\n",
        "            if self.use_reconst_loss:\n",
        "                g_loss += torch.mean((city - reconst_city)**2)\n",
        "\n",
        "            g_loss.backward()\n",
        "            self.g_optimizer.step()\n",
        "\n",
        "            # train gta-city-gta cycle\n",
        "            self.reset_grad()\n",
        "            fake_city = self.g21(gta)\n",
        "            out = self.d1(fake_city)\n",
        "            reconst_gta = self.g12(fake_city)\n",
        "            if self.use_labels:\n",
        "                g_loss = criterion(out, s_labels) \n",
        "            else:\n",
        "                g_loss = torch.mean((out-1)**2) \n",
        "\n",
        "            if self.use_reconst_loss:\n",
        "                g_loss += torch.mean((gta - reconst_gta)**2)\n",
        "\n",
        "            g_loss.backward()\n",
        "            self.g_optimizer.step()\n",
        "            \n",
        "            # print the log info\n",
        "            if (step+1) % self.log_step == 0:\n",
        "                print('Step [%d/%d], d_real_loss: %.4f, d_city_loss: %.4f, d_gta_loss: %.4f, '\n",
        "                      'd_fake_loss: %.4f, g_loss: %.4f' \n",
        "                      %(step+1, self.train_iters, d_real_loss.data[0], d_city_loss.data[0], \n",
        "                        d_gta_loss.data[0], d_fake_loss.data[0], g_loss.data[0]))\n",
        "\n",
        "            # save the sampled images\n",
        "            if (step+1) % self.sample_step == 0:\n",
        "                fake_gta = self.g12(fixed_city)\n",
        "                fake_city = self.g21(fixed_gta)\n",
        "                \n",
        "                city, fake_city = self.to_data(fixed_city), self.to_data(fake_city)\n",
        "                gta , fake_gta = self.to_data(fixed_gta), self.to_data(fake_gta)\n",
        "                \n",
        "                merged = self.merge_images(city, fake_gta)\n",
        "                path = os.path.join(self.sample_path, 'sample-%d-m-s.png' %(step+1))\n",
        "                path2 = os.path.join(self.sample_path, 'sample2-%d-m-s.png' %(step+1))\n",
        "                path3 = os.path.join(self.sample_path, 'sample3-%d-m-s.png' %(step+1))\n",
        "                path4 = os.path.join(self.sample_path, 'sample4-%d-m-s.png' %(step+1))\n",
        "                path5 = os.path.join(self.sample_path, 'sample5-%d-m-s.png' %(step+1))\n",
        "                print('.......', city.shape)\n",
        "                c = city.transpose(0, 2, 3, 1)\n",
        "                print(c.shape)\n",
        "                print(c[0])\n",
        "                #scipy.misc.imsave(path, merged)\n",
        "                #scipy.misc.imsave(path2, city[0])\n",
        "                #scipy.misc.imsave(path3, fake_gta[0])\n",
        "                #scipy.misc.imsave(path4, fake_city[0])\n",
        "                #scipy.misc.imsave(path5, gta[0])\n",
        "                \n",
        "                print ('saved %s' %path)\n",
        "                \n",
        "                merged = self.merge_images(gta, fake_city)\n",
        "                path = os.path.join(self.sample_path, 'sample-%d-s-m.png' %(step+1))\n",
        "                scipy.misc.imsave(path, merged)\n",
        "                print ('saved %s' %path)\n",
        "            \n",
        "            if (step+1) % 20 == 0:\n",
        "                # save the model parameters for each epoch\n",
        "                g12_path = os.path.join(self.model_path, 'g12-%d.pkl' %(step+1))\n",
        "                g21_path = os.path.join(self.model_path, 'g21-%d.pkl' %(step+1))\n",
        "                d1_path = os.path.join(self.model_path, 'd1-%d.pkl' %(step+1))\n",
        "                d2_path = os.path.join(self.model_path, 'd2-%d.pkl' %(step+1))\n",
        "                torch.save(self.g12.state_dict(), g12_path)\n",
        "                torch.save(self.g21.state_dict(), g21_path)\n",
        "                torch.save(self.d1.state_dict(), d1_path)\n",
        "                torch.save(self.d2.state_dict(), d2_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_KeEKrhNhu_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Script to load, process/augment data from GTA5 and CityScape datasets.abs\n",
        "# License: MIT\n",
        "# Author: Anderson Banihirwe\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from skimage import io\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class that\n",
        "    contains needed configuration settings.\"\"\"\n",
        "    def __init__(self, gta='./gta/images/',\n",
        "                 city='./city_real/',\n",
        "                 image_size=32, g_conv_dim=64, d_conv_dim=64,\n",
        "                 use_reconst_loss=True, use_labels=False, num_classes=None,\n",
        "                 train_iters=100, batch_size=64, num_workers=4, lr=0.0002,\n",
        "                 beta1=0.5, beta2=0.999, mode='train', model_path='models',\n",
        "                 sample_path='samples', log_step=10, sample_step=10):\n",
        "        self.gta_path = gta\n",
        "        self.city_path = city\n",
        "        self.image_size = image_size\n",
        "        self.g_conv_dim = g_conv_dim\n",
        "        self.d_conv_dim = d_conv_dim\n",
        "        self.use_reconst_loss = use_reconst_loss\n",
        "        self.train_iters = train_iters\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.mode = mode\n",
        "        self.model_path = model_path\n",
        "        self.sample_path = sample_path\n",
        "        self.log_step = log_step\n",
        "        self.sample_step = sample_step\n",
        "        self.use_labels = use_labels\n",
        "        self.num_classes = num_classes\n",
        "        self.lr = lr\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"Create a custom dataset object.\"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.root_dir))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir/self.files[idx]\n",
        "        image = io.imread(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "def get_loader(config, transfms=None):\n",
        "    \"\"\"Builds and returns Dataloader for GTA5 and CityScape dataset.\"\"\"\n",
        "    gta_path = pathlib.Path(config.gta_path)\n",
        "    city_path = pathlib.Path(config.city_path)\n",
        "\n",
        "    gta_dataset = CustomDataset(gta_path, transfms)\n",
        "    city_dataset = CustomDataset(city_path, transfms)\n",
        "    \n",
        "    dataloader_gta = DataLoader(gta_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
        "    dataloader_city = DataLoader(city_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
        "\n",
        "    return dataloader_gta, dataloader_city"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XzOcF_CldQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = Config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3iGRykJld-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transfms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSqebDYelsi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gta_loader, city_loader = get_loader(config, transfms=transfms)\n",
        "len(gta_loader)\n",
        "def show_batch(sample_batched):\n",
        "    images_batch = sample_batched\n",
        "    batch_size = len(images_batch)\n",
        "    im_size = images_batch.size(2)\n",
        "    grid = utils.make_grid(images_batch)\n",
        "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2gBXCe8xlxFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "solver = Solver(config, gta_loader, city_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Liaz_OLMlzYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVbe5Qfil50M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create directories if not exist\n",
        "if not os.path.exists(config.model_path):\n",
        "    os.makedirs(config.model_path)\n",
        "if not os.path.exists(config.sample_path):\n",
        "    os.makedirs(config.sample_path)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AKz0UxBQl8JU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "206adff2-ac2a-46a8-8618-86e230bd4dd4"
      },
      "cell_type": "code",
      "source": [
        "solver.train()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-ad90b845b08b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-86a4fcfe7dfb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# fixed city and gta for sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mfixed_gta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgta_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mfixed_city\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# loss if use_labels = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}