{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/andersy005/video-game-graphics-to-reality-and-back/blob/master/image_translation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "XFHViz75ndVG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install Colaboratory Tools"
      ]
    },
    {
      "metadata": {
        "id": "NYP068_SVSQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1372
        },
        "outputId": "9cc7acb8-d698-4f8a-f395-a0ddb700fbcc"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andersy005/colaboratory-tools.git --no-cache-dir --upgrade"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andersy005/colaboratory-tools.git\r\n",
            "  Cloning https://github.com/andersy005/colaboratory-tools.git to /tmp/pip-drfs62u6-build\n",
            "Requirement already up-to-date: pillow==4.0.0 in /usr/local/lib/python3.6/dist-packages (from colabtools==0.0.1)\n",
            "Requirement already up-to-date: scikit-image in /usr/local/lib/python3.6/dist-packages (from colabtools==0.0.1)\n",
            "Collecting seaborn (from colabtools==0.0.1)\n",
            "  Downloading seaborn-0.8.1.tar.gz (178kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 5.7MB/s \n",
            "\u001b[?25hRequirement already up-to-date: tensorboardX in /usr/local/lib/python3.6/dist-packages (from colabtools==0.0.1)\n",
            "Collecting torch (from colabtools==0.0.1)\n",
            "  Downloading torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (496.4MB)\n",
            "\u001b[K    44% |██████████████▏                 | 220.6MB 38.0MB/s eta 0:00:08"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 496.4MB 40.7MB/s \n",
            "\u001b[?25hRequirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (from colabtools==0.0.1)\n",
            "Requirement already up-to-date: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.0.0->colabtools==0.0.1)\n",
            "Collecting scipy>=0.17.0 (from scikit-image->colabtools==0.0.1)\n",
            "  Downloading scipy-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 50.0MB 38.0MB/s \n",
            "\u001b[?25hCollecting matplotlib>=1.3.1 (from scikit-image->colabtools==0.0.1)\n",
            "  Downloading matplotlib-2.2.2-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.6MB 40.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image->colabtools==0.0.1)\n",
            "Requirement already up-to-date: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from scikit-image->colabtools==0.0.1)\n",
            "Requirement already up-to-date: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->colabtools==0.0.1)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->colabtools==0.0.1)\n",
            "Collecting protobuf>=0.3.2 (from tensorboardX->colabtools==0.0.1)\n",
            "  Downloading protobuf-3.5.2.post1-cp36-cp36m-manylinux1_x86_64.whl (6.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 6.4MB 32.1MB/s \n",
            "\u001b[?25hCollecting pyyaml (from torch->colabtools==0.0.1)\n",
            "  Downloading PyYAML-3.12.tar.gz (253kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 43.5MB/s \n",
            "\u001b[?25hCollecting pytz (from matplotlib>=1.3.1->scikit-image->colabtools==0.0.1)\n",
            "  Downloading pytz-2018.4-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K    100% |████████████████████████████████| 512kB 34.6MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib>=1.3.1->scikit-image->colabtools==0.0.1)\n",
            "  Downloading kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n",
            "\u001b[K    100% |████████████████████████████████| 952kB 40.9MB/s \n",
            "\u001b[?25hRequirement already up-to-date: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->colabtools==0.0.1)\n",
            "Collecting python-dateutil>=2.1 (from matplotlib>=1.3.1->scikit-image->colabtools==0.0.1)\n",
            "  Downloading python_dateutil-2.7.2-py2.py3-none-any.whl (212kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 42.9MB/s \n",
            "\u001b[?25hRequirement already up-to-date: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->colabtools==0.0.1)\n",
            "Requirement already up-to-date: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image->colabtools==0.0.1)\n",
            "Collecting setuptools (from protobuf>=0.3.2->tensorboardX->colabtools==0.0.1)\n",
            "  Downloading setuptools-39.0.1-py2.py3-none-any.whl (569kB)\n",
            "\u001b[K    100% |████████████████████████████████| 573kB 38.3MB/s \n",
            "\u001b[?25hInstalling collected packages: seaborn, pyyaml, torch, colabtools, scipy, pytz, setuptools, kiwisolver, python-dateutil, matplotlib, protobuf\n",
            "  Found existing installation: seaborn 0.7.1\n",
            "    Uninstalling seaborn-0.7.1:\n",
            "      Successfully uninstalled seaborn-0.7.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running setup.py install for seaborn ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Found existing installation: PyYAML 3.11\n",
            "    Uninstalling PyYAML-3.11:\n",
            "      Successfully uninstalled PyYAML-3.11\n",
            "  Running setup.py install for pyyaml ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "  Found existing installation: colabtools 0.0.1\n",
            "    Uninstalling colabtools-0.0.1:\n",
            "      Successfully uninstalled colabtools-0.0.1\n",
            "  Running setup.py install for colabtools ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Found existing installation: scipy 0.19.1\n",
            "    Uninstalling scipy-0.19.1:\n",
            "      Successfully uninstalled scipy-0.19.1\n",
            "  Found existing installation: pytz 2016.7\n",
            "    Uninstalling pytz-2016.7:\n",
            "      Successfully uninstalled pytz-2016.7\n",
            "  Found existing installation: setuptools 36.2.7\n",
            "    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "  Found existing installation: matplotlib 2.1.2\n",
            "    Uninstalling matplotlib-2.1.2:\n",
            "      Successfully uninstalled matplotlib-2.1.2\n",
            "  Found existing installation: protobuf 3.5.2\n",
            "    Uninstalling protobuf-3.5.2:\n",
            "      Successfully uninstalled protobuf-3.5.2\n",
            "Successfully installed colabtools-0.0.1 kiwisolver-1.0.1 matplotlib-2.2.2 protobuf-3.5.2.post1 python-dateutil-2.7.2 pytz-2018.4 pyyaml-3.12 scipy-1.0.1 seaborn-0.8.1 setuptools-39.0.1 torch-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GSbGvD0qnX56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "\n",
        "Check to see if the data is already available. If not, download the data from google drive and extract the files from compressed files."
      ]
    },
    {
      "metadata": {
        "id": "67nT3iT4MQfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "if [ ! -f gta.tar.gz ]; then\n",
        "  echo \"File not found!\"\n",
        " \n",
        "  wget --header 'Host: doc-0o-58-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:59.0) Gecko/20100101 Firefox/59.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/drive/u/1/folders/1B56WZ20ODejt7MAwFr0a2HnMJ0fz4VlN' --header 'Cookie: AUTH_e1273drrbkihn7uunefac5g2nh6fppao=07610261954870412584|1523390400000|kf36r1s9jup16ems1p1f2sckdgrlvbhm; NID=123=lBPWjtG4k1sU7Dd0qsq5jpbqEiDrMBU8x0r6kdqXBCf-pCwxt9y7UdTTVaEFzLR7u5w-wq6dp0xKDTIsDb6QCnL0jNICERWUAuRHrxjQlpzo8gI8bqEpJJBDhN1T2RNR' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://doc-0o-58-docs.googleusercontent.com/docs/securesc/u8k4a259k8v0rijo1dv2q4t69g74544s/il57erfe3koja1994495ashvpr49mjfs/1523390400000/07610261954870412584/07610261954870412584/1gKCTPV_pCWaIEuiQ5IWP8rQSh040ezOL?h=11006290462901738094&e=download' --output-document 'city.tar.gz'\n",
        "  wget --header 'Host: doc-14-58-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:59.0) Gecko/20100101 Firefox/59.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/drive/u/1/folders/1B56WZ20ODejt7MAwFr0a2HnMJ0fz4VlN' --header 'Cookie: AUTH_e1273drrbkihn7uunefac5g2nh6fppao=07610261954870412584|1523390400000|kf36r1s9jup16ems1p1f2sckdgrlvbhm; NID=123=lBPWjtG4k1sU7Dd0qsq5jpbqEiDrMBU8x0r6kdqXBCf-pCwxt9y7UdTTVaEFzLR7u5w-wq6dp0xKDTIsDb6QCnL0jNICERWUAuRHrxjQlpzo8gI8bqEpJJBDhN1T2RNR' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://doc-14-58-docs.googleusercontent.com/docs/securesc/u8k4a259k8v0rijo1dv2q4t69g74544s/3le4pio11hb399ub230qat6883ggjv5n/1523390400000/07610261954870412584/07610261954870412584/1TxNprMLCTVnTWV9QIYDve5mv_DjOsCNb?h=11006290462901738094&e=download' --output-document 'gta.tar.gz'\n",
        "  tar -zxvf gta.tar.gz\n",
        "  tar -zxvf city.tar.gz\n",
        " \n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Mw2D349n43s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from colabtools.pytorch import datasets as cds\n",
        "from torch import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkBr4MzBn4z4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3c624396-2b15-4960-9d77-ad5eb400cd9b"
      },
      "cell_type": "code",
      "source": [
        "compose = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
        "        ])\n",
        "gta = cds.CustomDataset(root_dir='./gta/images/', transform=compose)\n",
        "gta_loader = utils.data.DataLoader(gta, num_workers=4, shuffle=True, batch_sampler=4)\n",
        "for i_batch, sample_batched in enumerate(gta_loader):\n",
        "  print(i_batch, sample_batched.size())\n",
        "  \n",
        "  if i_batch == 3:\n",
        "    cds.show_batch(sampled_batched)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-f5a7c30ec2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m#transforms.Normalize((.5, .5, .5), (.5, .5, .5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         ])\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./gta/images/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgta_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgta_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/colabtools/pytorch/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, transform)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RcHNp5m-akBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "02937d2a-8700-4642-8371-d72907d8f903"
      },
      "cell_type": "code",
      "source": [
        "help(cds.show_batch)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-402f2f69139b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'colabtools.pytorch.datasets' has no attribute 'show_batch'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Aufi8Z0kNExG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam \n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cI8qgsISNEs4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GTA_FOLDER ='./gta/images/'\n",
        "CITY_FOLDER = './city_real/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ikGeGGi_2m0S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LwWhNjklNrTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "rTaQAFTrgOJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnCQ6AWxlJXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class G12(nn.Module):\n",
        "    \"\"\"Generator for transfering from mnist to svhn\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G12, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        \n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        \n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "        \n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 3, 32, 32)\n",
        "        return out\n",
        "    \n",
        "class G21(nn.Module):\n",
        "    \"\"\"Generator for transfering from svhn to mnist\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G21, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        \n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        \n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "        \n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 1, 32, 32)\n",
        "        return out\n",
        "    \n",
        "class D1(nn.Module):\n",
        "    \"\"\"Discriminator for mnist.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D1, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out\n",
        "\n",
        "class D2(nn.Module):\n",
        "    \"\"\"Discriminator for svhn.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D2, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_KeEKrhNhu_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Script to load, process/augment data from GTA5 and CityScape datasets.abs\n",
        "# License: MIT\n",
        "# Author: Anderson Banihirwe\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from skimage import io\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class that\n",
        "    contains needed configuration settings.\"\"\"\n",
        "    def __init__(self, gta='./gta/images/',\n",
        "                 city='./city_real/',\n",
        "                 image_size=32, g_conv_dim=64, d_conv_dim=64,\n",
        "                 use_reconst_loss=True, use_labels=False, num_classes=None,\n",
        "                 train_iters=20, batch_size=64, num_workers=4, lr=0.0002,\n",
        "                 beta1=0.5, beta2=0.999, mode='train', model_path='models',\n",
        "                 sample_path='samples', log_step=10, sample_step=10):\n",
        "        self.gta_path = gta\n",
        "        self.city_path = city\n",
        "        self.image_size = image_size\n",
        "        self.g_conv_dim = g_conv_dim\n",
        "        self.d_conv_dim = d_conv_dim\n",
        "        self.use_reconst_loss = use_reconst_loss\n",
        "        self.train_iters = train_iters\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.mode = mode\n",
        "        self.model_path = model_path\n",
        "        self.sample_path = sample_path\n",
        "        self.log_step = log_step\n",
        "        self.sample_step = sample_step\n",
        "        self.use_labels = use_labels\n",
        "        self.num_classes = num_classes\n",
        "        self.lr = lr\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"Create a custom dataset object.\"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.root_dir))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir/self.files[idx]\n",
        "        image = io.imread(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "def get_loader(config, transfms=None):\n",
        "    \"\"\"Builds and returns Dataloader for GTA5 and CityScape dataset.\"\"\"\n",
        "    gta_path = pathlib.Path(config.gta_path)\n",
        "    city_path = pathlib.Path(config.city_path)\n",
        "\n",
        "    gta_dataset = CustomDataset(gta_path, transfms)\n",
        "    city_dataset = CustomDataset(city_path, transfms)\n",
        "    \n",
        "    dataloader_gta = DataLoader(gta_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
        "    dataloader_city = DataLoader(city_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
        "\n",
        "    return dataloader_gta, dataloader_city"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8jm0K8cgPda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import pickle\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torchvision import transforms, utils\n",
        "#from models.model import G12, G21\n",
        "#from models.model import D1, D2\n",
        "\n",
        "\n",
        "class Solver(object):\n",
        "    def __init__(self, config, gta_loader, city_loader):\n",
        "        self.gta_loader = gta_loader\n",
        "        self.city_loader = city_loader\n",
        "        self.g12 = None\n",
        "        self.g21 = None\n",
        "        self.d1 = None\n",
        "        self.d2 = None\n",
        "        self.g_optimizer = None\n",
        "        self.d_optimizer = None\n",
        "        self.use_reconst_loss = config.use_reconst_loss\n",
        "        self.use_labels = config.use_labels\n",
        "        self.num_classes = config.num_classes\n",
        "        self.beta1 = config.beta1\n",
        "        self.beta2 = config.beta2\n",
        "        self.g_conv_dim = config.g_conv_dim\n",
        "        self.d_conv_dim = config.d_conv_dim\n",
        "        self.train_iters = config.train_iters\n",
        "        self.batch_size = config.batch_size\n",
        "        self.lr = config.lr\n",
        "        self.log_step = config.log_step\n",
        "        self.sample_step = config.sample_step\n",
        "        self.sample_path = config.sample_path\n",
        "        self.model_path = config.model_path\n",
        "        self.build_model()\n",
        "        \n",
        "    def build_model(self):\n",
        "        \"\"\"Builds a generator and a discriminator.\"\"\"\n",
        "        self.g12 = G12(conv_dim=self.g_conv_dim)\n",
        "        self.g21 = G21(conv_dim=self.g_conv_dim)\n",
        "        self.d1 = D1(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n",
        "        self.d2 = D2(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n",
        "        \n",
        "        g_params = list(self.g12.parameters()) + list(self.g21.parameters())\n",
        "        d_params = list(self.d1.parameters()) + list(self.d2.parameters())\n",
        "        \n",
        "        self.g_optimizer = optim.Adam(g_params, self.lr, [self.beta1, self.beta2])\n",
        "        self.d_optimizer = optim.Adam(d_params, self.lr, [self.beta1, self.beta2])\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            self.g12.cuda()\n",
        "            self.g21.cuda()\n",
        "            self.d1.cuda()\n",
        "            self.d2.cuda()\n",
        "    \n",
        "    def merge_images(self, sources, targets, k=10):\n",
        "        _, _, h, w = sources.shape\n",
        "        row = int(np.sqrt(self.batch_size))\n",
        "        merged = np.zeros([3, row*h, row*w*2])\n",
        "        for idx, (s, t) in enumerate(zip(sources, targets)):\n",
        "            i = idx // row\n",
        "            j = idx % row\n",
        "            merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "            merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "        return merged.transpose(1, 2, 0)\n",
        "    \n",
        "    def to_var(self, x):\n",
        "        \"\"\"Converts numpy to variable.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cuda()\n",
        "        return Variable(x)\n",
        "    \n",
        "    def to_data(self, x):\n",
        "        \"\"\"Converts variable to numpy.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cpu()\n",
        "        return x.data.numpy()\n",
        "    \n",
        "    def reset_grad(self):\n",
        "        \"\"\"Zeros the gradient buffers.\"\"\"\n",
        "        self.g_optimizer.zero_grad()\n",
        "        self.d_optimizer.zero_grad()\n",
        "\n",
        "    def train(self):\n",
        "        gta_iter = iter(self.gta_loader)\n",
        "        city_iter = iter(self.city_loader)\n",
        "        iter_per_epoch = min(len(gta_iter), len(city_iter))\n",
        "        \n",
        "        # fixed city and gta for sampling\n",
        "        fixed_gta = self.to_var(gta_iter.next())\n",
        "        fixed_city = self.to_var(city_iter.next())\n",
        "        \n",
        "        # loss if use_labels = True\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        for step in range(self.train_iters+1):\n",
        "            # reset data_iter for each epoch\n",
        "            if (step+1) % iter_per_epoch == 0:\n",
        "                city_iter = iter(self.city_loader)\n",
        "                gta_iter = iter(self.gta_loader)\n",
        "            \n",
        "            # load gta and city dataset\n",
        "            gta = gta_iter.next() \n",
        "            gta = self.to_var(gta)\n",
        "            city = city_iter.next() \n",
        "            city = self.to_var(city)\n",
        "\n",
        "            if self.use_labels:\n",
        "                city_fake_labels = self.to_var(\n",
        "                    torch.Tensor([self.num_classes]*gta.size(0)).long())\n",
        "                gta_fake_labels = self.to_var(\n",
        "                    torch.Tensor([self.num_classes]*city.size(0)).long())\n",
        "            \n",
        "            #============ train D ============#\n",
        "            \n",
        "            # train with real images\n",
        "            self.reset_grad()\n",
        "            out = self.d1(city)\n",
        "            if self.use_labels:\n",
        "                d1_loss = criterion(out, m_labels)\n",
        "            else:\n",
        "                d1_loss = torch.mean((out-1)**2)\n",
        "            \n",
        "            out = self.d2(gta)\n",
        "            if self.use_labels:\n",
        "                d2_loss = criterion(out, s_labels)\n",
        "            else:\n",
        "                d2_loss = torch.mean((out-1)**2)\n",
        "            \n",
        "            d_city_loss = d1_loss\n",
        "            d_gta_loss = d2_loss\n",
        "            d_real_loss = d1_loss + d2_loss\n",
        "            d_real_loss.backward()\n",
        "            self.d_optimizer.step()\n",
        "            \n",
        "            # train with fake images\n",
        "            self.reset_grad()\n",
        "            fake_gta = self.g12(city)\n",
        "            out = self.d2(fake_gta)\n",
        "            if self.use_labels:\n",
        "                d2_loss = criterion(out, gta_fake_labels)\n",
        "            else:\n",
        "                d2_loss = torch.mean(out**2)\n",
        "            \n",
        "            fake_city = self.g21(gta)\n",
        "            out = self.d1(fake_city)\n",
        "            if self.use_labels:\n",
        "                d1_loss = criterion(out, city_fake_labels)\n",
        "            else:\n",
        "                d1_loss = torch.mean(out**2)\n",
        "            \n",
        "            d_fake_loss = d1_loss + d2_loss\n",
        "            d_fake_loss.backward()\n",
        "            self.d_optimizer.step()\n",
        "            \n",
        "            #============ train G ============#\n",
        "            \n",
        "            # train city-gta-city cycle\n",
        "            self.reset_grad()\n",
        "            fake_gta = self.g12(city)\n",
        "            out = self.d2(fake_gta)\n",
        "            reconst_city = self.g21(fake_gta)\n",
        "            if self.use_labels:\n",
        "                g_loss = criterion(out, m_labels) \n",
        "            else:\n",
        "                g_loss = torch.mean((out-1)**2) \n",
        "\n",
        "            if self.use_reconst_loss:\n",
        "                g_loss += torch.mean((city - reconst_city)**2)\n",
        "\n",
        "            g_loss.backward()\n",
        "            self.g_optimizer.step()\n",
        "\n",
        "            # train gta-city-gta cycle\n",
        "            self.reset_grad()\n",
        "            fake_city = self.g21(gta)\n",
        "            out = self.d1(fake_city)\n",
        "            reconst_gta = self.g12(fake_city)\n",
        "            if self.use_labels:\n",
        "                g_loss = criterion(out, s_labels) \n",
        "            else:\n",
        "                g_loss = torch.mean((out-1)**2) \n",
        "\n",
        "            if self.use_reconst_loss:\n",
        "                g_loss += torch.mean((gta - reconst_gta)**2)\n",
        "\n",
        "            g_loss.backward()\n",
        "            self.g_optimizer.step()\n",
        "            \n",
        "            # print the log info\n",
        "            if (step+1) % self.log_step == 0:\n",
        "                print('Step [%d/%d], d_real_loss: %.4f, d_city_loss: %.4f, d_gta_loss: %.4f, '\n",
        "                      'd_fake_loss: %.4f, g_loss: %.4f' \n",
        "                      %(step+1, self.train_iters, d_real_loss.data[0], d_city_loss.data[0], \n",
        "                        d_gta_loss.data[0], d_fake_loss.data[0], g_loss.data[0]))\n",
        "\n",
        "            # save the sampled images\n",
        "            if (step+1) % self.sample_step == 0:\n",
        "                fake_gta = self.g12(fixed_city)\n",
        "                fake_city = self.g21(fixed_gta)\n",
        "                \n",
        "                city, fake_city = self.to_data(fixed_city), self.to_data(fake_city)\n",
        "                gta , fake_gta = self.to_data(fixed_gta), self.to_data(fake_gta)\n",
        "                \n",
        "                merged = self.merge_images(city, fake_gta)\n",
        "                path = os.path.join(self.sample_path, 'sample-%d-m-s.png' %(step+1))\n",
        "                path2 = os.path.join(self.sample_path, 'sample2-%d-m-s.png' %(step+1))\n",
        "                path3 = os.path.join(self.sample_path, 'sample3-%d-m-s.png' %(step+1))\n",
        "                path4 = os.path.join(self.sample_path, 'sample4-%d-m-s.png' %(step+1))\n",
        "                path5 = os.path.join(self.sample_path, 'sample5-%d-m-s.png' %(step+1))\n",
        "               \n",
        "                scipy.misc.imshow(city.transpose(0, 2, 3, 1)[0])\n",
        "                scipy.misc.imshow(fake_city.transpose(0, 2, 3, 1)[0])\n",
        "                scipy.misc.imshow(gta.transpose(0, 2, 3, 1)[0])\n",
        "                scipy.misc.imshow(fake_gta.transpose(0, 2, 3, 1)[0])\n",
        "                #scipy.misc.imsave(path, merged)\n",
        "                #scipy.misc.imsave(path2, city[0])\n",
        "                #scipy.misc.imsave(path3, fake_gta[0])\n",
        "                #scipy.misc.imsave(path4, fake_city[0])\n",
        "                #scipy.misc.imsave(path5, gta[0])\n",
        "                \n",
        "                print ('saved %s' %path)\n",
        "                \n",
        "                merged = self.merge_images(gta, fake_city)\n",
        "                path = os.path.join(self.sample_path, 'sample-%d-s-m.png' %(step+1))\n",
        "                scipy.misc.imsave(path, merged)\n",
        "                print ('saved %s' %path)\n",
        "            \n",
        "            if (step+1) % 20 == 0:\n",
        "                # save the model parameters for each epoch\n",
        "                g12_path = os.path.join(self.model_path, 'g12-%d.pkl' %(step+1))\n",
        "                g21_path = os.path.join(self.model_path, 'g21-%d.pkl' %(step+1))\n",
        "                d1_path = os.path.join(self.model_path, 'd1-%d.pkl' %(step+1))\n",
        "                d2_path = os.path.join(self.model_path, 'd2-%d.pkl' %(step+1))\n",
        "                torch.save(self.g12.state_dict(), g12_path)\n",
        "                torch.save(self.g21.state_dict(), g21_path)\n",
        "                torch.save(self.d1.state_dict(), d1_path)\n",
        "                torch.save(self.d2.state_dict(), d2_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XzOcF_CldQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = Config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3iGRykJld-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transfms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSqebDYelsi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gta_loader, city_loader = get_loader(config, transfms=transfms)\n",
        "len(gta_loader)\n",
        "def show_batch(sample_batched):\n",
        "    images_batch = sample_batched\n",
        "    batch_size = len(images_batch)\n",
        "    im_size = images_batch.size(2)\n",
        "    grid = utils.make_grid(images_batch)\n",
        "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2gBXCe8xlxFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "solver = Solver(config, gta_loader, city_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Liaz_OLMlzYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVbe5Qfil50M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create directories if not exist\n",
        "if not os.path.exists(config.model_path):\n",
        "    os.makedirs(config.model_path)\n",
        "if not os.path.exists(config.sample_path):\n",
        "    os.makedirs(config.sample_path)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AKz0UxBQl8JU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "94744195-e1f4-4ff4-dbba-162645777416"
      },
      "cell_type": "code",
      "source": [
        "solver.train()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [10/20], d_real_loss: 0.3977, d_city_loss: 0.2266, d_gta_loss: 0.1711, d_fake_loss: 0.3707, g_loss: 1.8532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ad90b845b08b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-27b1ee34e232>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mpath5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample5-%d-m-s.png'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_city\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not execute image viewer.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not execute image viewer."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6PEVn92t8P1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqJ5-W5I8Q12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "35718571-b9cd-47e7-bf8d-28a4e6b1d1b0"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "\n",
        "'''\n",
        "    TensorBoard Data will be stored in './runs' path\n",
        "'''\n",
        "\n",
        "\n",
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        var_class = torch.autograd.variable.Variable\n",
        "        if type(d_error)==var_class:\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if type(g_error)==var_class:\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        var_class = torch.autograd.variable.Variable\n",
        "        if type(d_error)==var_class:\n",
        "            d_error = d_error.data.cpu().numpy()[0]\n",
        "        if type(g_error)==var_class:\n",
        "            g_error = g_error.data.cpu().numpy()[0]\n",
        "        if type(d_pred_real)==var_class:\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if type(d_pred_fake)==var_class:\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c7eddbcf73d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboardX'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cVl_Hk9u8gN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "88dee2d5-c092-483f-ccaf-60bc44e5f105"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1i1FTiyrgv8yGF8XCvABp8WdpWHpH3T5r  \u001b[0m\u001b[01;34mdatalab\u001b[0m/    \u001b[01;34mmodels\u001b[0m/   wget-log.1\r\n",
            "\u001b[01;34mcity_real\u001b[0m/                         \u001b[01;34mgta\u001b[0m/        \u001b[01;34msamples\u001b[0m/  wget-log.2\r\n",
            "city.tar.gz                        gta.tar.gz  wget-log\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4uf37S9j97Ju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        },
        "outputId": "b494d0aa-7888-4bdf-8d90-d7c4d7b83572"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow('samples/sample-10-s-m.png')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-061abd70062f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'samples/sample-10-s-m.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3101\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3102\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5129\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5132\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    616\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    617\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAFOCAYAAAA2HY52AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkB9hmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f669f5ba278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MdnmMr_p-AMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "04b8d97e-6575-4945-96ed-6dbc22023053"
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/andersy005/colaboratory-tools/blob/master/pytorch-install.sh"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-11 00:14:59--  https://github.com/andersy005/colaboratory-tools/blob/master/pytorch-install.sh\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘pytorch-install.sh’\n",
            "\n",
            "pytorch-install.sh      [ <=>                ]  34.18K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2018-04-11 00:14:59 (3.94 MB/s) - ‘pytorch-install.sh’ saved [34996]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8U-bOwDDjQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5028605b-7b2b-4737-d73b-967464e53de0"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1i1FTiyrgv8yGF8XCvABp8WdpWHpH3T5r  datalab     models\t\t   wget-log\r\n",
            "city_real\t\t\t   gta\t       pytorch-install.sh  wget-log.1\r\n",
            "city.tar.gz\t\t\t   gta.tar.gz  samples\t\t   wget-log.2\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eqpCLD2ODk7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a34fed8-e74c-4431-e235-f0fc7a7ea1db"
      },
      "cell_type": "code",
      "source": [
        "!./pytorch-install.sh"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: ./pytorch-install.sh: Permission denied\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x4k9A_oFDoqO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5a3784b-e741-4f92-a921-7527d2dfb74a"
      },
      "cell_type": "code",
      "source": [
        "!which bash"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MqNaeE-XDukc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f034f729-403e-4383-859f-0d8c6312900a"
      },
      "cell_type": "code",
      "source": [
        "!bash pytorch-install.sh"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytorch-install.sh: line 7: syntax error near unexpected token `newline'\r\n",
            "pytorch-install.sh: line 7: `<!DOCTYPE html>'\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aywtnjvuDxdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "37c0de4f-5d6d-4d37-a4c3-47ccf1ae7522"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'colaboratory-tools' already exists and is not an empty directory.\n",
            "Installing packages\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Finished installing Pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9o7QBP56D26s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJ_N8G4XEOTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20c67a8e-047a-4fbd-d243-7eb1278934e5"
      },
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.0.post4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "QQq37uXFEQLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab0a7d07-8a67-4851-9556-c44a89c52e33"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "WC9TP8NPEUQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}